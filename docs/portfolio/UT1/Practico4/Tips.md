# Unidad 1: RegresiÃ³n Lineal y RegularizaciÃ³n

## ğŸ“Œ PrÃ¡ctico: AnÃ¡lisis del Dataset Tips

### ğŸ¯ Objetivo
Aplicar tÃ©cnicas de **regresiÃ³n lineal**, **Ridge** y **Lasso** sobre el dataset de **propinas (Tips)**, con el fin de predecir el monto de la propina en funciÃ³n de variables como el total de la cuenta, dÃ­a, hora y si el cliente es fumador.  

Este prÃ¡ctico permite observar cÃ³mo la **regularizaciÃ³n** ayuda a mejorar la estabilidad de los modelos y, en el caso de Lasso, a realizar selecciÃ³n de variables.

### ğŸ”¹ Ridge Regression (L2 Regularization)
- Agrega una penalizaciÃ³n proporcional al **cuadrado de los coeficientes**.  
- No elimina variables, pero reduce el valor de los coeficientes grandes.  
- Ãštil cuando todas las variables aportan algo de informaciÃ³n.  

### ğŸ”¹ Lasso Regression (L1 Regularization)
- Agrega una penalizaciÃ³n proporcional al **valor absoluto de los coeficientes**.  
- Puede llevar algunos coeficientes a **0**, realizando selecciÃ³n automÃ¡tica de variables.  
- Ãštil cuando sospechamos que solo unas pocas variables son realmente relevantes.  

---

### ğŸ“‚ Archivos
- `TA4Tips.ipynb`: Notebook principal con el desarrollo de la prÃ¡ctica.  
- `data/tips.csv`: Dataset de propinas.  

---

### ğŸ“Š Proceso
1. **ImportaciÃ³n de librerÃ­as y carga de datos**  
   - Se trabajÃ³ con el dataset `tips.csv` de `seaborn`.  
   - Incluye 244 registros con 7 variables (numÃ©ricas y categÃ³ricas).  

2. **ExploraciÃ³n de datos (EDA)**  
   - EstadÃ­sticas descriptivas de `total_bill`, `tip` y `size`.  
   - AnÃ¡lisis de variables categÃ³ricas: sexo, fumador, dÃ­a, hora.  
   - RelaciÃ³n entre el total de la cuenta y la propina.  

3. **Preprocesamiento**  
   - ConversiÃ³n de variables categÃ³ricas con One-Hot Encoding.  
   - DivisiÃ³n en train/test.  
   - Escalamiento de variables numÃ©ricas.  

4. **Modelos de RegresiÃ³n y ClasificaciÃ³n**  
   - Se entrenaron y evaluaron:
     - **RegresiÃ³n Lineal**
     - **Ridge Regression**
     - **Lasso Regression**
     - **RegresiÃ³n LogÃ­stica (clasificaciÃ³n binaria: propina alta vs baja)**  
   - MÃ©tricas: RÂ², MAE, RMSE para regresiÃ³n; Accuracy, Precision, Recall y F1-score para clasificaciÃ³n.  

---

### ğŸ“ˆ Resultados
- **RegresiÃ³n Lineal**
  - ğŸ“Š MAE = 0.67  
  - ğŸ“Š RMSE = 0.84  
  - ğŸ“Š RÂ² = 0.437  

- **RegularizaciÃ³n**
  - ğŸ“Š Ridge â†’ RÂ² = 0.423  
  - ğŸ“Š Lasso â†’ RÂ² = 0.457  

- **ClasificaciÃ³n Binaria (Propina Alta vs Baja)**
  - Accuracy = 0.735  
  - Precision = 0.609  
  - Recall = 0.778  
  - F1-score = 0.683  
  - Matriz de confusiÃ³n:
    ```
    [[22  9]
     [ 4 14]]
    ```
  - El modelo identifica bien las propinas bajas (recall 0.71) y logra un buen desempeÃ±o para las propinas altas (recall 0.78).  

---

### ğŸš€ ReflexiÃ³n
Este prÃ¡ctico permitiÃ³ comparar distintos enfoques en un dataset pequeÃ±o y mixto (variables numÃ©ricas y categÃ³ricas):  
- **Ridge** estabiliza los coeficientes pero no mejora sustancialmente el RÂ² respecto a la regresiÃ³n lineal.  
- **Lasso** obtuvo el mejor desempeÃ±o al simplificar el modelo seleccionando automÃ¡ticamente las variables mÃ¡s relevantes.  
- La **clasificaciÃ³n binaria con RegresiÃ³n LogÃ­stica** alcanzÃ³ un 73% de accuracy, mostrando que el modelo es Ãºtil para distinguir entre propinas altas y bajas, aunque el recall de la clase alta aÃºn puede mejorar.  

En conclusiÃ³n, el dataset **Tips** es ideal para comprender cÃ³mo los mÃ©todos de regularizaciÃ³n (Ridge y Lasso) impactan en la predicciÃ³n y cÃ³mo un enfoque de clasificaciÃ³n puede aportar otra perspectiva en el anÃ¡lisis.  
---
